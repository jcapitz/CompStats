\relax 
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Actual Geyser data (left panel) vs. random sample of size $k=300$ generated from $\mathaccentV {hat}002{f}(x)_{ker}$, the kernel density estimator of the Geyser density (right panel). The random sample generated resembles the Geyser data fairly close. The idea behind using the finite mixture method based on a kernel density estimate is that we use each kernel generated as a "component distribution", where $c=n$ with $n$ being the number of data points used to estimate the density. That means that the weights for the finite mixture process are all equal and calculated as $\frac  {1}{n}$. In this example $n=299$, the number of data points in the Geyser dataset.}}{1}}
\newlabel{q19 fig1}{{1}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces In this implementation of density estimation using the kernel method the smoothing constant is chosen to be $h=1.06\mathaccentV {hat}002{\sigma }n^{\frac  {1}{5}}$ based on Silverma's rule. As we can see, the kernel density estimate appears much more smoother that that of the finite mixture. This is expected because the model chosen for the finite mixture closely resembles the actual data, so one would expect that the finite mixture estimate would closely resemble the data. But what if the model chosen does not include all the actual components in the mixture?. In the next graph we choose a different smoothing parameter for the kernel estimate.}}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces In this density estimation implementation we increase the roughness of the kernel estimate by choosing a new $h^{*}=\frac  {h}{4}$. Now we see that by increasing roughness we actually get a closer match between the finite mixture and the kernel density estimate. This example emphasizes the importance of our choice of $h$ when estimating densities.}}{4}}
\newlabel{inclass fig1}{{3}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The left panel is the histogram of the random sample generated using the kernel based finite mixture random sampling algorithm. On the right is the random sample generated by the finite mixture estimate using an initial 3-component model with means: $\mathaccentV {hat}002{\mu _1}=-1$, $\mathaccentV {hat}002{\mu _2}=4$, $\mathaccentV {hat}002{\mu _3}=9$, variances: $\mathaccentV {hat}002{\sigma }_1^2=\mathaccentV {hat}002{\sigma }_2^2=\mathaccentV {hat}002{\sigma }_3^2=1$, and weights: $\mathaccentV {hat}002{p_1}=0.5$, $\mathaccentV {hat}002{p_2}=0.25$, $\mathaccentV {hat}002{p_3}=0.25$. The random samples seem fairly consistent, which indicates that both approaches are valid and consistent. }}{7}}
\newlabel{inclass fig2}{{4}{7}}
